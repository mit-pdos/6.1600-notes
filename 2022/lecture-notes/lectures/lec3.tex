In the last chapter, we focused on authenticating people---ensuring that
a person (or a request on behalf of that person) is likely who they claim to be.
In this chapter, we will focus on authenticating
files, code, and other data.
When we say that we want to authenticate a file,
we mean that we want to verify that the file's
contents are exactly as they were when we or
someone we trust last viewed them.
The key new tool we use to do so is a \textit{collision-resistant hash function}. 

\section{Intuition: Collision resistance}
\begin{definition}[Hash Function]
	A hash function $H$ maps a bitstring of any length onto a fixed-size space of outputs. $H: \bin^* \rightarrow \bin^{\lambda}$.
\end{definition}

In order for a hash function to be \textit{collision-resistant}, we want it to be the case that for any input, the generated output should be \textquote{unique.} Of course, it cannot really be unique---we are mapping infinitely many inputs onto finitely many outputs---but we want it to be \textit{computationally infeasible} to find a 
pair of distinct inputs that have the same hash values (a ``\textit{collision}'').

\begin{framed}
  \textbf{Security goal for collision-resistant hash functions:}
  It is \textquote{computationally infeasible} to find two distinct inputs 
  to a collision resistant hash function that hash to the same value.
\end{framed}

Collision-resistant hash functions let you authenticate 
a long message $m$ by authenticating a short fixed-length string $H(m)$.
We often call the hash value $H(m)$ a \emph{digest}.

\subsection{Applications}
\subsubsection{Secure File Mirroring}
Often a user wants to download large files (e.g., software updates) from a far-away server.
To speed up this process, a company or Internet-service provider may set up local \emph{mirrors}
of the remote files.
Users can then download the files from the nearby mirror instead of the far-away server.
However, without additional security measures, the mirror may 
server users a different file than the one the mirror fetched from the origin server.
If the mirror is malicious, it can, for example, trick the user into installing
a backdoored software update.
(We saw an attack based on mirrors in~\cref{sec:intro:xcode}.)

To protect against a malicious mirror, we can add some authentication on the file that the mirror hosts.
Say that the origin server publishes a large software update~$f$.
The origin server will send the file $f$ to its mirrors and the origin
server itself will serve the hash digest $d\gets H(f)$ to anyone who asks for it.
A user who wants to fetch the update can download $d$ from the origin server directly---this
will be fast since the digest is tiny.
Then, the client can fetch the update itself from a (potentially untrustworthy) mirror.
When the client receives a file $\hat f$ from the mirror, it can check that $d = H(\hat f)$
to ensure that $\hat f$ is the true software update.
If $H$ is collision resistant, then if the hash value $H(\hat f)$ matches the origin server's digest $d$,
the files are almost certainly identical.

\subsubsection{Subresource Integrity}
If a program fetches a file from some content
delivery network, it can store the hash of that
file locally and use it to verify that the
contents of the file did not change since the
application was developed.

\subsubsection{Outsourced File Storage}
If you want to store your files on a cloud
provider, you want to be sure that the cloud
provider does not maliciously modify the files
without you noticing. To make sure of this, you
can store $H(\text{files})$ locally, which takes
very little storage space. Then, when you
redownload your files locally, you can recompute
the hash to verify that they were not tampered
with.

\section{Defining collision resistance (slightly more formally)}
An adversary's goal in breaking a collision
resistant hash function is to find a collision---a
pair of values $m_0, m_1 \in \zo^*$ such that
$m_0 \neq m_1$ and $H(m_0) = H(m_1)$.

\begin{definition}[Collision Resistance]
	A function $H: \bin^* \rightarrow \bin^{\lambda}$ is collision-resistant 
  if for all \textquote{efficient} adversaries $\calA$, we have that:
  \[ \Pr[H(m_0) = H(m_1), m_0 \neq m_1: (m_0, m_1) \leftarrow \calA()] \leq \text{``negligible''} \]
\end{definition}

In words, this means that the probability of finding a collision is so small that no efficient adversary could hope to do it.

There are two ways of thinking about the terms ``efficient'' and ``negligible'' that 
we use in this definition---one mindset we use in practice and the other mindset we use in theory.

\begin{itemize}
	\item In theory$\ldots$
		\begin{itemize}
      \item All of our cryptographic constructions are parameterized by an integer $\lambda \in \{1, 2, 3, \dots\}$
            that we call the \textit{security parameter}.
            So instead of a single collision-resistant hash function $H$, we have a family of functions
            $\{ H_1, H_2, H_3, \dots \}$, where the function $H_\lambda$ has $\lambda$-bit output. 
			\item An \textquote{efficient} algorithm is a randomized algorithm that runs in time polynomial in $\lambda$.
			\item A \textquote{negligible} function is one that grows slower than the inverse of every polynomial---a function that is $O(\frac{1}{\lambda^c})$
            for all constants $c \in \mathbb{N}$.  
		\end{itemize}
	\item In practice$\ldots$
		\begin{itemize}
			\item We use a fixed hash function $H$ with a fixed-length output,
        which might be as 256 or 512 bits.
			\item An \textquote{efficient} adversary is one that runs in time $\leq 2^{128}$.
			\item A \textquote{negligible} probability is some very small constant, like one smaller than $2^{-128}$.
		\end{itemize}
\end{itemize}

\subsection{Where do these numbers come from?}

\begin{table}[htpb]
	\centering
	\caption{Big numbers in terms of hashes}
	\label{tab:exp-work}

	\begin{tabular}{rl}
		$2^{30}$ & operations/second on a laptop \\
		$2^{58}$ & ops/sec on Fugaku supercomputer \\
		$2^{68}$ & hashes/second on the Bitcoin network (as of Fall 2022) \\
    $2^{92}$ & hashes/yr on the Bitcoin network (TODO: Cite)\\
		$2^{114}$ & hashes required to use enough energy to boil the ocean \\
		$2^{140}$ & hashes required to use one year of the sun's energy \\
	\end{tabular}
\end{table}

\begin{table}[htpb]
	\centering
	\caption{Exponents as probabilities}
	\label{tab:exp-probability}

	\begin{tabular}{rl}
		$2^{-1}$ & fair coin lands heads \\
		$2^{-28}$ & probability of winning Mega Millions \\
		$2^{-128}$ & will never happen \\
	\end{tabular}
\end{table}

The takeaway is that if our hash function has a $2^{-128}$ chance of a collision. We can be extremely sure that a collision will never occur.

\section{Constructing a CRHF}
Pretty much every CRHF that exists today follows the same two-step approach:

\begin{enumerate}
	\item Build a small CRHF $H_{small}: \bin^{2\lambda} \rightarrow \bin^\lambda$. This step is \textquote{more art than science}, and involves doing things that seem collision resistant and testing the result extensively to see if it seems breakable. The current standard for fast collision-resistant hashing is SHA256, which was designed by the NSA in 2001. Hash Functions can also be build from \textquote{nice} assumptions about hardness of problems such as factoring of large numbers, but hash functions based on these assumptions tend to be very slow so are almost never used in practice.
	\item Use $H_{\text{small}}$ to construct $H: \bin^* \rightarrow \bin^\lambda$. This can be done very cleanly, and one approach is the \textquote{Merkle-Damgard} approach below.
\end{enumerate}

\subsection{Merkle-Damgard}
Merkle-Damgard is based on splitting the message into $\lambda$-sized blocks $[m_1, \ldots, m_n]$ and successively hashing them together.

First, start with a bitstring $0^\lambda$. and compute $h_1 = H_{\text{small}}(0^\lambda||m_1)$. Next, compute $h^2 = H_{small}(h_1||m_2)$, $h_3$, and so on through $h_n$. Finally, compute $h_{\text{final}} = H_{small}(h_n, n)$ and output $h_{\text{final}}$.

We won't prove this here, but we can use the fact that $H_{small}$ is collision-resistant to prove that $H$ must also be collision-resistant. The basic idea of the proof is to show that given a collision in $H$, we can easily compute a collision in $H_{\text{small}}$. 

\subsection{The Birthday Paradox}
An important thing to note when dealing wiht hash functions is the birthday paradox, which says that given a hash function with $\lambda$-bit output, you can alays find a collision in time $O(\sqrt{2^\lambda}) = O(2^{\frac{\lambda}{2}})$. This means that a collision can be found in $2^\frac{\lambda}{2}$---if you want it to take $2^{128}$ to find a collision, you need 256-bit output from your hash function.

\subsection{Domain Separation}
Consider the case where we have a one-input CRHF (such as SHA2) $H: \bin^* \rightarrow \bin^{256}$ and want to construct a two-input CRHF $H_2(x, y)$. 

\textbf{Bad Idea}: An obvious solution may be to just concatenate the two values, so that $H_2(x, y) = H(x || y)$. However, this allows two different pairs of messages to hash to the same value---$H_2(\text{"key", "value"}) = H_2(\text{"ke", "yvalue"})$. Both Amazon and Flickr had a bug arising from this---they concatenated all parameters before hashing, and had parameters such that two different intents had the same concatenation.

\subsection{Length-Extension}
Recall the concept of Message Authentication Codes (MAC) from the last lecture---a code that can be sent along with a message to verify that the message was not changed.

Last time, we used $MAC(k, m) = H(k || m)$ as a very simple construction of a MAC. However, this construction has an easy attack---given $\text{MAC}(k, m)$, it is easy to compute $\text{MAC}(k, m||m')$ without knowing $k$ if using a hash function built with the Merkle-Damgard construction. To do this, you can hash the output of $\text{MAC}(k, m)$ with two more blocks---a new message $m''$ and another length block. Now, we have computed $\text{MAC}(k, m||m')$ where $m'$ is the original length block plus some custom message without knowing $k$. 

This lesson here is that we were using a hash function that was only guaranteed to be collision-resistant, and assumed it had other properties (such as that it is guaranteed to be difficult to compute the hash of an extension of the original message).
% the diagram here would be very helpful.

\section{Applications}
\subsection{Merkle Trees}
In many cases, we would like to authenticate many files quickly. If we have $N$ files to authenticate, one option would be to store the hash of all $N$ files on the server. However, in this case the client needs to download every file in order to authenticate a single file. Another option would be to store the hashes for each file on the server, but then authenticating many files becomes difficult. A better option is to build a tree out of the files. 

I think that the diagram from lecture is pretty important here. But the basic idea is that we build a tree by hashing together pairs of files, then hash each pair of hashes and so on until we eventually end up with a single root hash. Then, in order to verify any single file we need to download $\log N$ hashes, and to verify all files we only need to download a single root hash.


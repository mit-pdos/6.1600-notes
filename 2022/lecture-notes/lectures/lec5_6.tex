\todo{Rewrite in terms of one-bit Lamport signatures}

In the last section, our strategy for
authentication depended on two parties sharing a
secret key.
In that discussion, we completely left
out of the picture how these parties should
exchange this secret key.
Our implication was that they
went to some private room and exchanged the key in
secret, but in many cases this is not practical:
if they could whisper a key, why not just whisper the message?

Luckily, there is a way to get around this requirement for a shared secret using \emph{public-key cryptography}.\cite{DH76} % TODO: cite DH
\marginnote{The original Diffie-Hellman paper from 1976, which introduced
public-key cryptography, is a fascinating read.}

\section{Definitions}
The basic idea of public-key cryptography, applied
to authentication, is that each party will
generate two linked keys---a secret signing key
and a public verification key.
The verification key will be good enough to verify that a signature
is valid, but not to generate new signatures.

\begin{definition}[Signature Scheme]
	A signature scheme is associated with a message space $\calM$ and three efficient algorithms $(\Gen, \Sign, \Ver)$.

      \marginnote{In theoretical papers, people will write $\Gen(1^\lambda)$ to indicate that the key-generation
      algorithm takes as input a length-$\lambda$ string of ones.
      This is just a hack to make the input given to $\Gen$ $\lambda$ bits long so that the
      $\Gen$ algorithm can run in time polynomial in its input length: $\poly(\lambda)$.
      If we express $\lambda$ in binary, then $\Gen(\lambda)$ gets a $\log_2 \lambda$-bit input
      and can only run in time $\poly(\log \lambda)$.
      This distinction is really unimportant, but if you see the $1^\lambda$ notation, you will
      now know what it means.}
	\begin{itemize}
    \item $\Gen(\lambda) \to (\sk, \vk)$.
      The key-generation algorithm as input a security parameter $\lambda \in \N$ and outputs a secret signing key $\sk$ and public verification key $\vk$.
      The algorithm $\Gen$ runs in time $\poly(\lambda)$.
    \item $\Sign(\sk, m) \to \sigma$.
      The signing algorithm takes as input a secret key $\sk$ and a message $m \in \calM$, and outputs a signature $\sigma$.
    \item $\Ver(\vk, m, \sigma) \to \zo$.
      The signature-verification algorithm takes as input a public verification key $\vk$, a message $m \in \calM$, and a signature $\sig$, 
      and outputs $\bin$, indicating acceptance or rejection.
	\end{itemize}
	
\end{definition}

For a signature scheme to be useful, a correct verifier must always accept messages from an
honest signer. Formally, we have:

\begin{definition}[Digital signatures: Correctness]
  A digital-signature scheme $(\Gen, \Sign, \Ver)$ is \emph{correct} if,
  for all messages $m \in \calM$:
  \[ \Pr\big[\Ver(\vk, m, \Sign(\sk, m)) = 1 \colon (\sk, \vk) \gets \Gen(\lambda) \big] = 1. \]
\end{definition}

The standard security notion for digital signatures is very similar
to that for MACs (\cref{def:mac-sec}).
The only difference here is that a digital-signature scheme splits the single
secret MAC key into two keys: a secret signing key and a public verification key.
Otherwise the definition is essentially identical.

\begin{definition}[Digital signatures: Security -- existential unforgeability under chosen message attack]\label{def:sig-sec}
  A digital-signature scheme $(\Gen, \Sign, \Ver)$ is \emph{secure} if
  all efficient adversaries win the following security 
  game with only negligible probability:
  \begin{itemize}[noitemsep]
    \item The challenger runs $(\sk, \vk) \gets \Gen(\lambda)$ and sends $\vk$ to the adversary.
    \item For $i = 1, 2, \dots$  (polynomially many times)
      \begin{itemize}
        \item The adversary sends a message $m_i \in \calM$ to the challenger.
        \item The challenger replies with $\sigma_i \gets \Sign(\sk, m_i)$.
      \end{itemize}
    \item The adversary outputs a message-signature pair $(m^*, \sigma^*)$.
    \item The adversary wins if $\Ver(\vk, m^*, \sigma^*) = 1$ and $m^* \not \in \{m_1, m_2, \dots\}$.
  \end{itemize}
\end{definition}

Notice that the security definition here allows an attacker, given a valid
message-signature pair $(m, \sigma)$ to produce additional valid message-signature
pairs on the same message: $(m, \sigma'), (m, \sigma''), \dots$.
Standard digital-signature schemes, such as the elliptic-curve digital signature
algorithm (EC-DSA) have this property.

In some applications, we want to prohibit an attacker from finding \emph{any}
new message-signature pair. We call this security notion ``\emph{strong} existential unforgeability under chosen message attack.'' 

The definition is the same as in \cref{def:sig-sec} except that we require
the adversary to find a valid-message signature pair $(m^*, \sigma^*)$
such that $(m^*, \sigma^*) \not \in \{ (m_1, \sigma_1), (m_2, \sigma_2), \dots \}$.

\section{Constructing a Signature Scheme}
In the following sections, we will show how to construct a digital-signature
scheme from any one-way function (\cref{def:owf}).

We will generate a signature scheme that is secure, but that has a relatively large
signatures and public keys: to achieve security against attackers running
in time $2^\lambda$, this signature scheme has signatures of $O(\lambda^2)$ bits.
Widely used modern digital signature schemes (e.g., EC-DSA) have signatures
of $O(\lambda)$ bits.\marginnote{One benefit of the signature scheme that 
we present here is that---unlike EC-DSA, RSA, DSA, and other widely used
signature schemes---this one is plausibly secure even against \emph{quantum}
adversaries.\todo{Cite NIST PQ signature schemes and compare}
}

We will construct this scheme in three stages:

\begin{enumerate}
	\item Construct a \emph{one-time secure} signature scheme for \emph{fixed-length messages}.
        With this scheme, an attacker who sees two signatures under the same signing key can forge signatures.
        In addition, the secret signing key for this scheme will be larger than the size of the message 
        being signed.
      \item Construct a \emph{one-time secure} scheme for \emph{arbitrary-length messages}.
        Here, we construct a one-time signature scheme whose secret signing key is independent of 
        the length of the signed message.

      \item Construct a \emph{many-time secure} scheme (i.e., a fully secure one under 
        \cref{def:sig-sec}) for \emph{arbitrary-length messages}.
        This last scheme is a fully secure and fully functional digital-signature scheme.
\end{enumerate}


\section{One-time-secure Signatures (Lamport Signatures)} \label{sec:lamport}

In this section we give a very simple and elegant construction 
of one-time-secure digital signatures, due to Lamport.\cite{L79}
Before giving the construction, we define one-time security for 
digital-signature schemes.
This signature scheme is not generally useful on its own, but is
useful as a building block.

\begin{definition}[Digital signatures: One-Time Security]\label{def:sig-once}
A digital-signature scheme $(\Gen, \Sign, \Ver)$ over message space $\calM$ is \emph{one-time secure} if all efficient adversaries win
the following game with negligible probability:
  \begin{itemize}[noitemsep]
    \item The challenger generates $(\sk, \vk) \leftarrow \Gen(\lambda)$ and sends $\vk$ to the adversary.
    \item The adversary sends the challenger \emph{single} message $m \in \calM$.
    \item The challenger responds with $\sig = \Sign(\sk, m)$.
    \item The adversary outputs $(m^*, \sig^*)$.
    \item The adversary wins the game if $\Ver(\vk, m^*, \sig^*) = 1$ and $m^* \neq m$.
\end{itemize}
\end{definition}

\paragraph{Lamport signatures.}
We now construct a one-time secure signature scheme for messages in $\bin^n$,
for some fixed message length $n \in \N$. 
To do this, we will define the following algorithms, which make use of a
one-way function $f \colon \calX \to \calY$:
\begin{itemize}
  \item $\Gen() \to (\sk, \vk)$. 
    \marginnote{In this construction, we leave the security parameter $\lambda$
    implicit.
    To be fully formal, $\Gen$ would take $\lambda$ an input.
    The one-way function $f$ and its domain $\calX$ would both
    depend on $\lambda$. So we would write $f_\lambda$ and $\calX_\lambda$.
    }
    Choose $2n$ random elements from $\calX$,
    the domain of the one-way function $f$.
    Arrange these values in to a $2 \times n$
    matrix, which forms the secret signing key $\sk$.
    The public verification key just consists of the $2n$
    images of these values under the one-way function $f$:
\[ \sk \gets \begin{pmatrix}
	x_{10} & \ldots & x_{n0} \\
	x_{11} & \ldots & x_{n1} \\
	\end{pmatrix},\quad \vk \gets \begin{pmatrix}
	f(x_{10}) & \ldots & f(x_{n0}) \\
	f(x_{11}) & \ldots & f(x_{n1}) \\
\end{pmatrix}.\]
	\item $\Sign(\sk, m) \to \sigma$ outputs $(x_{1m_1}, \ldots x_{nm_n})$, where $m_1 \dots m_n$ 
    are the individual bits of the length-$n$ message $m \in \zo^n$.
	\item $\Ver(\vk, m, \sig) \to \zo$ parses the 
    the message into bits $m = m_1\dots m_n \in \zon$ and
    the signature $\sig$ into its individual symbols $\sig = (x_1^*, \ldots x_n^*) \in \calX^n$.
    The signing routine accepts if, for all $i \in \{1, \dots, n\}$:
    \begin{equation}
      f(x^*_i) = \vk_{i,m_i}.\label{eq:lamport}
    \end{equation}
    In other words, the routine accepts if applying the one-way function $f$ to each symbol
    of the signature matches the corresponding value in the verification key.
    (Otherwise, the signing routine rejects.)
\end{itemize}

This signature scheme has relatively large keys:
the verification key, in particular consists of $2n$ values,
where each is of length $\Omega(\lambda)$ bits.
So the total length is roughly $2n\lambda$ bits---much
longer than the $n$-bit message being signed.

In addition, notice that an adversary who sees signatures
on even two messages can forge signatures on messages of its choice.
In particular:
\begin{itemize}[noitemsep]
  \item The adversary first asks for a signature on the message $m_0 = 0^n$.
It receives $\sig_0 = (x_{10}, \ldots, x_{n0})$.
  \item The adversary then then asks for a signature on the message $m_1 = 1^n$.
    It receives $\sig_1 = (x_{11}, \ldots, x_{n1})$.
  \item At this point, the adversary has the entire secret signing key! 
\end{itemize}
However, we will show that this scheme is indeed one-time secure.

\begin{claim} 
The Lamport signature scheme is one-time secure under the
assumption that $f$ is a one-way function.
\end{claim}
\marginnote{Remember that if $\classP = \classNP$, 
one-way functions, and also digital signature schemes, do not exist. 
So any proof of security of a digital-signature scheme will require
some sort of cryptographic assumption.}

In cryptography, we generally prove these security
claims by \emph{reduction}: we will show that
if there exists an efficient adversary $\calA$
that breaks the security of our scheme,
then we can construct an efficient adversary $\calB$ 
that breaks one of our assumptions.
If we do this, we have reached a contradiction to one
of our assumptions, so the first adversary cannot exist.

\begin{proof}[Proof of Claim]
Suppose there exists an adversary $\A$ that wins the 
one-time-security game of \cref{def:sig-once} with non-negligible probability $\epsilon$.
That is, the adversary can produces $(m^*, \sig^*)$ such that $\Ver(\vk, m^*, \sig^*) = 1$ and $m \neq m^*$ given only $\sig = \Sign(\sk, m)$.
We can then construct an adversary $\B$ that can use $\A$ to 
invert the one-way function.

\marginnote{Lamport's construction shows that if one-way functions
exist, then so do digital signatures.
Can you show that if digital signatures exist, then so do one-way
functions?}

In particular, our adversary $\calB$ will use algorithm $\calA$
as a subroutine to invert the one-way function.
We will show that if $\calA$ wins in the one-time signature security
game often, then algorithm $\calB$ will invert the one-way function
often, which is a contradiction.

Assume our one-way function is of the form $f \colon \calX \to \calY$
and that the Lamport signature scheme is on $n$-bit messages.
The one-way-function adversary $\calB$ operates as follows:
\begin{itemize}[noitemsep]
  \item The adversary $\calB$ is given a point $y \in \calY$
    and its task is to produce a preimage of $y$ under $f$. 
  \item The adversary $\calB$ generates a signing keypair as follows:
    \begin{itemize}[noitemsep]
      \item It runs the key-generation algorithm for the Lamport signature scheme $(\sk, \vk) \gets \Gen()$.
      \item The adversary chooses a random value $i^* \getsr \{1, \dots, n\}$
            and a random bit $\beta^* \getsr \zo$.
          \item The adversary sets $\vk_{i^*,\beta^*} \gets y$.
            That is, it inserts the one-way-function point it must invert
            into a random location in the verification key.
    \end{itemize}
  \item The adversary then sends the verification key $\vk$ to the Lamport-signature adversary $\calA$.
  \item The adversary $\calA$ asks for the signature on a message $m = m_1 m_2 \dots m_n \in \zon$.
  \item If $m_{i^*} = \beta^*$, then algorithm $\calB$ cannot produce a valid signature on the message
        $m$ and it outputs FAIL.
  \item Otherwise, the algorithm $\calB$ returns the signature $\sigma = (\sk_{1,m_1}, \dots, \sk_{n,m_n}) \in \calX^n$
        to algorithm $\calA$.
  \item Algorithm $\calA$ then produces a forged message-signature pair $(m^*, \sigma^*)$,
        where $m \neq m^*$.
  \item Algorithm $\calB$ parses $m^* = m^*_1 \dots m^*_n \in \zon$
        and $\sigma^* = \sigma^*_1 \dots \sigma^*_n \in \calX^n$. Then:
        \begin{itemize}[noitemsep]
          \item If $m_{i^*} = m_i$, algorithm $\calB$ outputs FAIL.
          \item Otherwise, algorithm $\calB$ outputs $x \gets \sigma^*_{i^*} \in \calX$.
        \end{itemize}
\end{itemize}

First, notice that whenever $(m^*, \sigma^*)$ is a valid message-signature
pair and whenever algorithm $\calB$ does not output FAIL, algorithm $\calB$
outputs a preimage $x \in \calX$ of point $y \in \calY$ under the one-way function $f$.
That is because, by the verification relation (\ref{eq:lamport}) for Lamport signatures,
\[f(x) = f(\sigma^*_{i^*}) = \vk_{i^*,m^*_{i^*}} = \vk_{i^*, 1 - m_i} = \vk_{i^*, \beta^*} = y.\]

Now, we must show that algorithm $\calB$ does not output FAIL too often.
Since algorithm $\calB$ chooses the values $i^*$ and $\beta^*$ at random,
and since the adversary $\calA$ behavior is \emph{independent} of these values,
we can say:
  \begin{itemize}
    \item the probability of the first failure event is $1/2$,
          since there are two possible choices of $m_{i^*}$ and only 
          one of these is bad, and 
    \item the probability of the second failure event is at most $1/n$,
          since $m$ and $m^*$ must differ in at least one of $n$ bits,
          and there is a $1/n$ probability that this differing bit is
          at index $i^*$.
  \end{itemize}

The events that $\calA$ breaks the signature scheme
and that either of these failures occur are all \emph{independent}.
Then if $\calA$ breaks the one-way function with probability $\epsilon$,
our one-way-function adversary $\calB$
inverts the one-way function with probability
\[ \epsilon_\text{one-way} = \epsilon \cdot \frac{1}{2} \cdot \frac{1}{n}.\]

The probability of either bad is at most $1/2 + 1/n$,
by the union bound.
Therefore if algorithm $\calA$ breaks one-time security of Lamport's
scheme with probability $\epsilon$,
If $\epsilon$ is non-negligible, then $\epsilon_\text{one-way} = \epsilon/2n$
is also non-negligible, and we have a contradiction.
\end{proof}

% LECTURE 6

\section{A one-time signature scheme for arbitrary-length messages}
In the scheme above, the keys scale with the size of the input. To adapt our scheme from above into a scheme that works on arbitrary-length messages without the key growing arbitrarily large, we will use a strategy called hash-and-sign. In essence, we will pass our message through a hash function to generate a fixed-size digest before applying the scheme above. To do so, we will show a more general construction of a scheme for arbitrary-length messages from one for bounded-length messages.

\begin{claim}
Given a collision-resistant hash function $h: \bin^* \rightarrow \bin^{n=256}$ and a signature scheme $(\Gen, \Sign, \Ver)$ for message space $\calM = \bin^n$ (such as the one in \S\ref{sec:lamport}), there exists a signature scheme $(\Gen', \Sign', \Ver')$ for $\calM' = \bin^*$ as follows:

\begin{itemize}
	\item $\Gen'$: generate $(\sk, \vk)$ as $\Gen$ and output $\sk' = (\sk, h), \vk' = (\vk, h)$. Note that we include the hash function as part of the keys.
	\item $\Sign'((\sk, h), m) = \Sign(sk, h(m))$. We hash the message using the given hash function before passing it to the original signing function.
	\item $\Ver'((\vk, h), m, \sig) = \Ver(\vk, h(m), \sig)$. We use the original $\Ver$ to check that the tag matches \emph{hash} of the original message.
\end{itemize}
\end{claim}

\subsubsection{Security Intuition}
Suppose $\exists \A$ that breaks $(\Gen', \Sign', \Ver')$, meaning that given $((m_1, \sig_1, \ldots, (m_t, \sig_t))$, $\A$ is able to forge $(m^*, \sig^*)$ such that $m^* \notin \set{m_1, \ldots, m_t}$. There are then two cases for what the adversary could have found:

\begin{enumerate}
	\item $h(m^*) \notin \set{h(m_1), \ldots, h(m_t)}$. Since the message that we pass to the underlying signature scheme is $h(m)$, this means $\A$ has found a valid signature for $h(m)$ under the original scheme $(\Gen, \Sign, \Ver)$ after seeing only signatures of $h(m_1)\neq h(m), \ldots, h(m_t)\neq h(m_t)$. This breaks the security of the underlying scheme, which is a contradiction!
	\item $h(m^*) \in \set{h(m_1), \ldots, h(m_t)}$. If this is the case, there is some $i \in [t]$ such that $h(m^*) = h(m_i)$. However, $h$ is collision-resistant as in the definition, so this is a contradiction!
\end{enumerate}

\subsubsection{Application to Lamport}
We can apply the above to our Lamport scheme from above. We can fix our input to the Lamport scheme at, for example, 256 bits, and then run messages through a hash function that outputs 256 bits before passing them to the Lamport scheme. Note, however, that this does not affect the \emph{security} of our scheme---it is still only one-time secure.

\subsubsection{Hash \& Sign}
This paradigm is called hash \& sign, and is very common---practically, hashing is a very cheap operation while signing turns out to be very expensive. So it is common to hash a message before signing it in order to reduce the size of the message that must be signed. \marginnote{Recall that we faced a similar problem in our MAC construction. Why not use hash \& MAC there? The reason is that we used AES as our PRF, which takes input of $\bin^{128}$. As explained by the birthday paradox, it is possible to find a collision in an output space of size $2^{128}$ in only time $2^64$! This does not provide sufficient security for practical use, as it would be quite practical to find collisions. If we had a version of AES that outputted 256 bits, we could indeed apply hash \& sign.}

In practice, this strategy can actually \emph{increase} the security of our hash function. As shown in case 2 above, it is absolutely crucial that the hash function used is collision-resisant: if not, an adversary can find messages that cause collisions, and then a signature for one message will also be a valid signature for the other. However, in practice we think of hash functions like AES as \emph{random oracles}. This is much stronger than collision resistance, and allows us to treat the output of the hash function as truly random.

Recall that our security definition involves the attacker requesting signatures over messages of its choice. If we pass a message through a hash function before passing it to our signature scheme, however, we effectively randomize the message---the adversary can no longer control the input to the scheme. This allows us to define another meaningful definition of security:

\begin{definition}[Digital signatures: security against random message attacks]
	Any efficient adversary given $\vk$ and a list of random message-signature pairs $((m_1, \sig_1), \ldots, (m_t, \sig_t))$ cannot generate $(m^*, \sig^*)$ such that $\Ver(\vk, m^*, \sig^*) = 1$ and $m^* \notin \set{m_1, \ldots, m_t}$.
\end{definition}

Note that this definition is \emph{not} good enough on its own---an adversary often does have the ability to generate signatures for messages of his choice. However, paired with a hash function modeled as a random oracle, this definition becomes very useful---if the inputs are passed through the hash function before they are passed to the signature scheme, they become effectively random. We can even relax the definition further without losing practicality: by the same logic, with hash function in front of the signature scheme, what the adversary needs to sign is really not a message of their choise, but is the \emph{hash} of a message of their choice---effectively a random value.

\begin{definition}[Digital signatures: random security against random message attacks] \label{def:signatures_random_security}
	Any efficient adversary given $\vk$ and a list of random message-signature pairs $((m_1, \sig_1), \ldots, (m_t, \sig_t))$ and random $m^* \notin \set{m_1, \ldots, m_t}$ cannot generate $\sig^*$ such that $\Ver(\vk, m^*, \sig^*) = 1$.
\end{definition}

It is possible to formally argue that given a signature scheme satisfying definition \ref{def:signatures_random_security} and a random oracle, we can construct a scheme satisfying existential unforgeability under chosen message attacks.

\section{From one-time security to many-time security}
After applying the hash \& sign strategy above to our Lamport scheme, we have a signature scheme that is one-time secure for messages of arbitrary length. In order for the scheme to be useful and satisfy our security definition, we need to be able to sign polynomially many messages with a single key pair. To do this, we will use a construction very similar to he Merkle tree construction we have seen before.

We will show how to do this for a message space of size $\bin^n$, but hash \& sign can be applied to make this work for arbitrarily-length messages. We will first show an inefficient construction, and then use a PRF to make it practical.

We first generate a single key pair for every possible message in the message space: $2^n$ total $(\sk_i^n, \vk_i^n)$ pairs for $i \in \bin^n$. These will be the leaves of our tree. For every two adjacent keys, we will then generate a key pair ($2^{n-1}$ pairs total) Then continue for all $j \in [0, \ldots, n]$, where the keys for each $j$ form layer $n-j$ of the tree (with leaves at level $n$).

% TODO: diagram of tree

Importantly, every key in the tree will be used to sign only one message ever: the key at non-leaf nodes will only ever sign the pair of its children, and the key at leaf nodes will only ever be used to sign the corresponding message. 

To sign a given message, we generate the signature as 

% TODO: finish this explanation.

\subsection{Improving Inefficiency}
In the scheme above, we required $O(2^n)$ keys for our secret key. This is far too many keys to be pracical, but we still need to be able to use each of these keys to sign a given message. To bridge this gap, we will use a PRF to generate these secret keys \textquote{on the fly}.

Given a one-time secure signature scheme $(\Gen, \Sign, \Ver)$:

\begin{itemize}
	\item $\Gen'$: generate $(\sk, \vk) \leftarrow \Gen()$ for one-time scheme and a random PRF key $k$. Output $\vk' = \vk$ and $\sk' = (\sk, k)$.
	\item $\Sign'$: % finish
\end{itemize}

\section{Overview}


The goal of this course is to give you an overview of the 
most important ``Big Ideas'' on securing computer systems.
Throughout the course, we will touch on ideas from the fields
of computer security, cryptography, and (to some extent)
computer systems.

\iffalse
\textbf{Big Idea}: Big ideas for securing computers.
\begin{itemize}
	\item Lectures: ask questions!
	\item Labs (coding) + psets (theory)
	\item Midterm + final
\end{itemize}
\fi

\section{What is Security?}
Security is a very broad property, but generally
the goal of computer security 
is to ensure that a particular computer system is 
``behaves correctly'' even in the
face of an ``adversary'' (or ``attacker'') whose goal is to foil the
system.
\sidenote{We will use the terms ``adversary'' and ``attacker''
interchangeably throughout this course.}

To achieve this goal, we will need some kind of
systematic plan.
That is, we will have to carefully define 
what it means for our system to ``behave correctly''
and we will have to specify the class of 
``adversaries'' against which we want to defend.

For the purposes of this course, we will typically
structure our plan in terms of three components:
a \emph{goal}, 
a \emph{threat model}, and
an \emph{implementation}.

\begin{itemize}
  \item \textbf{Goal:} 
    The security goal defines what we want our system to achieve.
    For example, a informal goal might be that ``only Alice can read the file $F$,''
    or ``if anyone tampers with the file $F$, Alice will detect it.''
    As you will learn throughout the course, figuring out exactly what your
    security goal should be is often quite subtle and challenging.

  \item \textbf{Threat model:} 
    The threat model (or ``adversary model'') specifies the class of 
    adversaries against which we want to defend.
    Or, put another way, the threat model specifies the adversary's power:
    what can the adversary do to break our security goal?
    By defining a threat model, we can make it
    tractable to achieve a security goal. 
    For example, in analyzing the security of a password-based login system,
    our threat model might specify that 
    the adversary can guess passwords, but cannot steal the server.
  \item \textbf{Implementation:}
    The implementation is how we achieve the goal.
    For example, we might set permissions on a file $F$, 
    use Linux to enforce those permissions, 
    and require two-factor authentication to access the system.
\end{itemize}

Together, the goal and the threat model create our
\textit{definition} of security.\sidenote{When you read
about security failures in the news, it is worth trying
to understand the failure arose from a problem with the
goal, the threat model, or the implementation.}
As such, they
cannot be ``wrong''---the goal might turn out to
not be exactly what we needed, 
the threat model might not have captured all of
the attacks that our system might actually face
in the real world, 
but together the goal and threat model define 
the security properties that we set out to achieve.
The implementation, on the other hand, can definitely be wrong---if 
the implementation does not guarantee the goal under the threat model, due to bugs or oversights or supply chain vulnerabilities or anything else, the implementation has a mistake.

\subsection{Security is Hard}

Building secure systems is challenging.
There are at least two broad reasons for this.

\paragraph{Secure systems must defend against worst-case behavior.}
First, a secure system must defend against
\emph{all possible attacks} within the scope of 
the threat model.
In contrast, when we are just concerned about functionality or
correctness, we are typically satisfied with a system 
that performs well 99.99999\% of the time.
In other words, security is concerned with \emph{worst-case behavior},
while correctness is usually about \emph{average-case behavior}

For example, suppose that we have
a student-information system that should achieve the security
goal: ``\textbf{only} TAs can access grades.''
It is easy to test if a TA can
access grades (correctness), but it is much harder to test whether
there is some sequence of interactions that allow
\textit{anyone else} to access the grades (security).

\paragraph{An implementation can never defend against all possible threats.}
When we specify a threat model, we delimit the set of adversaries 
against which our implementation must defend.
But real-world adversaries can behave in ways that are 
outside of our threat model and thereby violate our security goals.

For example, someone besides a TA might be able to
access the grades by:
\begin{itemize}
	\item finding a bug in the server software,
	\item breaking into a TA's office,
	\item stealing the password to an administrator's account,
	\item tricking a TA into disclosing grades,
	\item breaking the server's cryptography,
	\item getting a job at the registrar and making herself a TA.
\end{itemize}

And the list never ends. Because our threat model cannot capture all
possible threats, \textbf{security is never perfect}.
There will essentially always be \textit{some} attacker than can break your system.

This is why we need a threat model: the threat
model defines what kinds of attacks we worry about
and which we decide are out of scope.

\subsection{Designing a threat model}
Designing a threat model is all about comparing
the cost of defending against an attack with the
cost of that attack if it were to happen.
It is almost always impractical to exactly calculate
these costs, but this framework is useful
conceptually.
Cheap defenses that block major
holes are likely to be worth implementing, but
defending against an esoteric RF side channel that
could leak unimportant information is likely not.

Building a threat model always requires iterating---you will not get it right on the first try.
There is likely to be some type of attack that you didn't consider at first that ends up being important.

\subsection{Techniques}
We will focus largely in this class on techniques
that have a big payoff---methods of developing
software and tools to use that eliminate entire
classes of attacks (or make them much harder). 

\section{Examples}
\subsection{Bad Goals}
\subsubsection{Business-class airfare}
An airline tried to add value to their
business-class tickets by allowing ticket-holders to 
change the ticket (i.e., the departure date, origin, and destination)
at any time with no fee.
One customer realized that they could board the flight
\textit{then} change their ticket.
The customer could then take an unlimited number of
business-class flights for the price of one.

In this case, the airline's goal did not meet
their real needs---perhaps they needed to add
an additional goal of the form ``every time someone takes a flight,
we get paid.''

\subsubsection{Sarah Palin's Email}
Sarah Palin had a Yahoo email account, and Yahoo
used security questions for password reset---their
goal may have been something like ``no one can
reset a user's password unless they know all of
the answers to the user's security questions.''
(The security questions are typically things like
``What is your mother's maiden name?'')
As it turned out, it was possible to find the answer
to all of Palin's account-recovery security questions 
on her wikipedia page.
Yahoo's implementation may have been perfect, but their
goal did not provide any meaningful security for certain users.

\subsubsection{Instruction Set Architecture (ISA) Specification}
When defining ISAs for processors, designers did
not think that timing was important, and
processors could take a variable number of cycles
to execute a particular instruction.
This had big benefits for performance and for
compatibility, but as we'll talk about later in
the semester, researchers have recently exploited
this timing variability to perform sophisticated
attacks on wide ranges of processors. The
processor implementation matched the
specification, but the specification itself
allowed for this attack.

\subsubsection{Fairfax VA School}
This school had a system similar to Canvas with a somewhat complex structure: each teacher is in charge of some class, each class has many students, and each student has many files. Teachers cannot access student's files, and there is also a superintendent that has access to all the files. Teachers are able to change their students' passwords, and are able to add students to their class. It turned out that a teacher could add the superintendent as a student, change the superintendent's password, and then access all files via the superintendent's account.

\subsubsection{Matt Honan's Gmail Account}
A journalist for wired named Matt Honan had a Gmail account. Gmail's reset password feature avoided security questions, and instead used a backup email account. Honan used an Apple email for this.

Apple's reset password feature then required the user's address and the last four digits of the credit card number. The attacker was able to find his address publically, but could not easily find his credit card digits.

Amazon, which knew his credit card number, required a full CC\# in order to reset an account. However, Amazon allowed buying something for a certain account without logging in, so long as you provide a new credit card number. It also allowed \textit{saving} this credit card number to Amazon's account. After the attacker saved their own credit card number to Honan's Amazon account, they were able to reset Honan's Amazon password and access his Amazon account. The attacker was then able to see the last four digits of Honan's real credit card within his Amazon account, use that to reset his Apple mail account, and then use that to reset Honan's Gmail account.

This complex chain can be very hard to reason about, but these interactions ultimately define security.

\subsection{Problematic Assumptions}
\subsubsection{Assuming specific strategy: CAPTCHA}
CAPTCHAs were designed to be expensive to automate, but easy for a human to read. Indeed it would be expensive to build an OCR system for these, but attackers did not do this. Instead, they set up farms in countries where the cost of labor is cheap and paid people to solve CAPTCHAs. The result is that it costs some fraction of a cent to solve a CAPTCHA. This is still useful, but not nearly as useful as the original intent.

\subsubsection{Computational Power: DES}
There used to be an encryption standard called DES that had $2^{56}$ possible keys. At the time that it was designed, this was considered secure, but today it is easily crackable with a modern computer. As a result, MIT had to switch from DES to Kerberos for authentication.

\subsubsection{Dependencies: 2FA via SMS}
Many 2FA systems use a text message for authentication, but an attacker then just needs to convince the clerk at the AT\&T store to give them a new SIM card for your phone number.

\subsubsection{Software Versions: Xcode}
iPhone apps are normally created and compiled on a developer's machine, sent to Apple's App Store, and sent to iPhones from there. iPhone apps are created using a tool called Xcode that is normally downloaded from Apple servers. However, Xcode is a big piece of software and for developers behind China's firewall, it was very slow to download. Someone within China set up a much faster mirror of Xcode, and lots of developers in China used the version of Xcode from this mirror. However, this mirror was not serving exactly Apple's version of Xcode---instead, it was serving a slightly modified version of Xcode that would inject some malicious code into every app that was compiled with it. This took a long time to detect. 

\subsection{Problematic Implementations}
Bugs, misconfigurations, and other mistakes are the most common cause of security issues. A rule of thumb to keep in mind is that every 1000 lines of code will have around 1 bug. This is a very rough estimate, but the basic idea is that more code will have more bugs. An effective strategy to reduce security vulnerabilities is to reduce the amount of code in your system.

\subsubsection{Missing Checks: iCloud}
Apple's iCloud performs many functions---email, calendar, storage, and Find my iPhone. Each of these had their own way of logging in, but across all of them a common goal was to limit the attacker's ability to guess a user's password. To do this, they added rate limiting to all the login interfaces, allowing something like only 10 login attempts per hour---but they forgot the Find my iPhone login interface. Because this authentication code was duplicated all over the place, there were many places to remember to add this rate limiting, but the attacker only needed one weak login interface to brute-force a password. In general, avoiding this repition will make it much easier to build a secure system.

\subsubsection{Insecure Defaults}
When you set up a new service, they almost always come with some defaults to make the setup simpler. Wi-Fi routers come with default passwords, AWS S3 buckets come with default permissions, and so on. These defaults can be convenient, but they are very important to security because many people will forget or neglect to change the default. Because of this, the default becomes the way that the system operates. In order to build a secure system, it is important that the default is secure.



\section{Improving}
\subsection{Goals and Threat Models}
\begin{itemize}
	\item Creating simpler, more general goals
	\item Avoiding assumptions (such as "no one else will be able to get a user's SIM card") by redesigning the system
	\item Learn and iterate
	\item Defense in Depth: don't rely on one single defense for all your security---it is useful to use backup defenses to guard against bugs that will inevitably come up in one defense.
\end{itemize}

\subsection{Implementation}
\begin{itemize}
	\item A simpler system will lead to fewer problems
	\item Factor out security-critical part (for example, hardware security keys).
	\item Reuse well-designed code, such as well-tested crypto libraries
	\item Understand the corner cases
\end{itemize}




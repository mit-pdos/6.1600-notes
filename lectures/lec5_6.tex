\chapter{Digital Signatures}

In the last section, our strategy for
authentication depended on two parties sharing a
secret key.
In that discussion, we completely left
out of the picture how these parties should
exchange this secret key.
Our implication was that they
went to some private room and exchanged the key in
secret, but in many cases this is not practical:
if they could whisper a key, why not just whisper the message?

Luckily, there is a way to get around this requirement for a shared secret using \emph{public-key cryptography}.\cite{DH76} % TODO: cite DH
\marginnote{The original Diffie-Hellman paper from 1976, which introduced
public-key cryptography, is a fascinating read.}

\section{Definitions}
The basic idea of public-key cryptography, applied
to authentication, is that each party will
generate two linked keys---a secret signing key
and a public verification key.
The verification key will be good enough to verify that a signature
is valid, but not to generate new signatures.

\begin{definition}[Signature Scheme]
	A signature scheme is associated with a message space $\calM$ and three efficient algorithms $(\Gen, \Sign, \Ver)$.

      \marginnote{In theoretical papers, people will write $\Gen(1^\lambda)$ to indicate that the key-generation
      algorithm takes as input a length-$\lambda$ string of ones.
      This is just a hack to make the input given to $\Gen$ $\lambda$ bits long so that the
      $\Gen$ algorithm can run in time polynomial in its input length: $\poly(\lambda)$.
      If we express $\lambda$ in binary, then $\Gen(\lambda)$ gets a $\log_2 \lambda$-bit input
      and can only run in time $\poly(\log \lambda)$.
      This distinction is really unimportant, but if you see the $1^\lambda$ notation, you will
      now know what it means.}
	\begin{itemize}
    \item $\Gen(\lambda) \to (\sk, \vk)$.
      The key-generation algorithm as input a security parameter $\lambda \in \N$ and outputs a secret signing key $\sk$ and public verification key $\vk$.
      The algorithm $\Gen$ runs in time $\poly(\lambda)$.
    \item $\Sign(\sk, m) \to \sigma$.
      The signing algorithm takes as input a secret key $\sk$ and a message $m \in \calM$, and outputs a signature $\sigma$.
    \item $\Ver(\vk, m, \sigma) \to \zo$.
      The signature-verification algorithm takes as input a public verification key $\vk$, a message $m \in \calM$, and a signature $\sig$, 
      and outputs $\bin$, indicating acceptance or rejection.
	\end{itemize}
	
\end{definition}

For a signature scheme to be useful, a correct verifier must always accept messages from an
honest signer. Formally, we have:

\begin{definition}[Digital signatures: Correctness]
  A digital-signature scheme $(\Gen, \Sign, \Ver)$ is \emph{correct} if,
  for all messages $m \in \calM$:
  \[ \Pr\big[\Ver(\vk, m, \Sign(\sk, m)) = 1 \colon (\sk, \vk) \gets \Gen(\lambda) \big] = 1. \]
\end{definition}

The standard security notion for digital signatures is very similar
to that for MACs (\cref{def:mac-sec}).
The only difference here is that a digital-signature scheme splits the single
secret MAC key into two keys: a secret signing key and a public verification key.
Otherwise the definition is essentially identical.

\begin{definition}[Digital signatures: Security -- existential unforgeability under chosen message attack]\label{def:sig-sec}
  A digital-signature scheme $(\Gen, \Sign, \Ver)$ is \emph{secure} if
  all efficient adversaries win the following security 
  game with only negligible probability:
  \begin{itemize}[noitemsep]
    \item The challenger runs $(\sk, \vk) \gets \Gen(\lambda)$ and sends $\vk$ to the adversary.
    \item For $i = 1, 2, \dots$  (polynomially many times)
      \begin{itemize}
        \item The adversary sends a message $m_i \in \calM$ to the challenger.
        \item The challenger replies with $\sigma_i \gets \Sign(\sk, m_i)$.
      \end{itemize}
    \item The adversary outputs a message-signature pair $(m^*, \sigma^*)$.
    \item The adversary wins if $\Ver(\vk, m^*, \sigma^*) = 1$ and $m^* \not \in \{m_1, m_2, \dots\}$.
  \end{itemize}
\end{definition}

Notice that this   security definition does not guarantee that an attacker cannot forge a new signature on a message that it has already seen a signature of. 
Namely, given a valid
message-signature pair $(m, \sigma)$ an adversary may be able to produce additional valid message-signature
pairs on the same message: $(m, \sigma'), (m, \sigma''), \dots$.

In some applications, we want to prohibit an attacker from finding \emph{any}
new message-signature pair. We call this security notion ``\emph{strong} existential unforgeability under chosen message attack.''  
The definition is the same as in \cref{def:sig-sec} except that we require
the adversary to find a valid-message signature pair $(m^*, \sigma^*)$
such that $(m^*, \sigma^*) \not \in \{ (m_1, \sigma_1), (m_2, \sigma_2), \dots \}$.  Standard digital-signature schemes, such as the elliptic-curve digital signature
algorithm (EC-DSA) is believed to have this strong security property.

\section{Constructing a Signature Scheme}
In the following sections, we will show how to construct a digital-signature
scheme from any one-way function (\cref{def:owf}).

We will generate a signature scheme that is secure, but that has relatively large
signatures and public keys: to achieve security against attackers running
in time $2^\lambda$, this signature scheme has signatures of $O(\lambda^2)$ bits.
Widely used modern digital signature schemes (e.g., EC-DSA) have signatures
of $O(\lambda)$ bits.\marginnote{One benefit of the signature scheme that 
we present here is that---unlike EC-DSA, RSA, DSA, and other widely used
signature schemes---this one is plausibly secure even against \emph{quantum}
adversaries.\todo{Cite NIST PQ signature schemes and compare}
}

We will construct this scheme in three stages:

\begin{enumerate}
	\item Construct a signature scheme for signing a \emph{single bit}.  

        \item Construct a \emph{one-time secure} signature scheme for signing a \emph{fixed length} messages.
        With this scheme, an attacker who sees two signatures under the same signing key can forge signatures.
        In addition, the secret signing key for this scheme will be larger than the size of the message 
        being signed.
      \item Construct a \emph{one-time secure} scheme for \emph{arbitrary-length messages}.
        Here, we construct a one-time signature scheme whose secret signing key is independent of 
        the length of the signed message.

      \item Construct a \emph{many-time secure} scheme (i.e., a fully secure one under 
        \cref{def:sig-sec}) for \emph{arbitrary-length messages}.
        This last scheme is a fully secure and fully functional digital-signature scheme.
\end{enumerate}

\section{Constructing a Signature Scheme for Signing a Single Bit}

This signature scheme is not useful on its own, and is given only as a step towards the final construction.  It uses as a building block a one-way function $f:\calX\rightarrow\calY$.  Recall that $f$ a one-way function if it is easy to compute but hard to invert; namely there is an efficient algorithm that given $x\in\calX$ outputs $f(x)$, and at the same time any efficient algorithm given $y=f(x)$ for a random $x\leftarrow \cal X$, finds an inverse $x'\in\calX$ such that $f(x')=f(x)$ with only negligible probability.  

\begin{itemize}
  \item $\Gen() \to (\sk, \vk)$. 
    \marginnote{In this construction, we leave the security parameter $\lambda$
    implicit.
    To be fully formal, $\Gen$ would take $\lambda$ an input.
    The one-way function $f$ and its domain $\calX$ would both
    depend on $\lambda$. So we would write $f_\lambda$ and $\calX_\lambda$.
    }
    Choose two random elements $x_0, x_1$ from $\calX$ and let $(y_0,y_1)=(f(x_0),f(x_1))$.  Output $\sk=(x_0,x_1)$ and $\vk=(y_0,y_1)$.
    
	\item $\Sign(\sk, b) \to \sigma$.  Parse $\sk=(x_0,x_1)$ and output $\sigma=x_b$, 
	\item $\Ver(\vk, b, \sig) \to \zo$. Parse $\vk=(y_0,y_1)$ and output~$1$ if and only if $f(\sig)=y_b$. 
    (Otherwise, the signing routine rejects.)
\end{itemize}


\section{One-time-secure Signatures (Lamport Signatures)} \label{sec:lamport}

In this section we give a very simple and elegant construction 
of a one-time-secure digital signature scheme, due to Lamport.\cite{L79}
The construction is a straightforward generalization of  the signature scheme constructed above:  Each message is signed bit-by-bit, where each bit is signed using a fresh and independently generated secret key. 


Before giving the construction, we define one-time security for 
digital-signature schemes.
This signature scheme is not generally useful on its own, but is
useful as a building block.

\begin{definition}[Digital signatures: One-Time Security]\label{def:sig-once}
A digital-signature scheme $(\Gen, \Sign, \Ver)$ over message space $\calM$ is \emph{one-time secure} if all efficient adversaries win
the following game with negligible probability:
  \begin{itemize}[noitemsep]
    \item The challenger generates $(\sk, \vk) \leftarrow \Gen(\lambda)$ and sends $\vk$ to the adversary.
    \item The adversary sends the challenger \emph{single} message $m \in \calM$.
    \item The challenger responds with $\sig = \Sign(\sk, m)$.
    \item The adversary outputs $(m^*, \sig^*)$.
    \item The adversary wins the game if $\Ver(\vk, m^*, \sig^*) = 1$ and $m^* \neq m$.
\end{itemize}
\end{definition}

\paragraph{Lamport signatures.}
We now construct a one-time secure signature scheme for messages in $\bin^n$,
for some fixed message length $n \in \N$. 
To do this, we will define the following algorithms, which make use of a
one-way function $f \colon \calX \to \calY$:
\begin{itemize}
  \item $\Gen() \to (\sk, \vk)$. 
    %\marginnote{In this construction, we leave the security parameter $\lambda$ implicit. To be fully formal, $\Gen$ would take $\lambda$ an input. The one-way function $f$ and its domain $\calX$ would both     depend on $\lambda$. So we would write $f_\lambda$ and \calX_\lambda$.    }
    Choose $2n$ random elements from $\calX$,
    the domain of the one-way function $f$.
    Arrange these values in to a $2 \times n$
    matrix, which forms the secret signing key $\sk$.
    The public verification key just consists of the $2n$
    images of these values under the one-way function $f$:
\[ \sk \gets \begin{pmatrix}
	x_{10} & \ldots & x_{n0} \\
	x_{11} & \ldots & x_{n1} \\
	\end{pmatrix},\quad \vk \gets \begin{pmatrix}
	f(x_{10}) & \ldots & f(x_{n0}) \\
	f(x_{11}) & \ldots & f(x_{n1}) \\
\end{pmatrix}.\]
	\item $\Sign(\sk, m) \to \sigma$ outputs $(x_{1m_1}, \ldots x_{nm_n})$, where $m_1 \dots m_n$ 
    are the individual bits of the length-$n$ message $m \in \zo^n$.
	\item $\Ver(\vk, m, \sig) \to \zo$ parses the 
    the message into bits $m = m_1\dots m_n \in \zon$ and
    the signature $\sig$ into its individual symbols $\sig = (x_1^*, \ldots x_n^*) \in \calX^n$.
    The signing routine accepts if, for all $i \in \{1, \dots, n\}$:
    \begin{equation}
      f(x^*_i) = \vk_{i,m_i}.\label{eq:lamport}
    \end{equation}
    In other words, the routine accepts if applying the one-way function $f$ to each symbol
    of the signature matches the corresponding value in the verification key.
    (Otherwise, the signing routine rejects.)
\end{itemize}

This signature scheme has relatively large keys:
the verification key, in particular consists of $2n$ values,
where each is of length $\Omega(\lambda)$ bits.
So the total length is roughly $2n\lambda$ bits---much
longer than the $n$-bit message being signed.

In addition, notice that an adversary who sees signatures
on even two messages can forge signatures on messages of its choice.
In particular:
\begin{itemize}[noitemsep]
  \item The adversary first asks for a signature on the message $m_0 = 0^n$.
It receives $\sig_0 = (x_{10}, \ldots, x_{n0})$.
  \item The adversary then then asks for a signature on the message $m_1 = 1^n$.
    It receives $\sig_1 = (x_{11}, \ldots, x_{n1})$.
  \item At this point, the adversary has the entire secret signing key! 
\end{itemize}
However, we will show that this scheme is indeed one-time secure.

\begin{claim} 
The Lamport signature scheme is one-time secure under the
assumption that $f$ is a one-way function.
\end{claim}
\marginnote{Remember that if $\classP = \classNP$, 
one-way functions, and also digital signature schemes, do not exist. 
So any proof of security of a digital-signature scheme will require
some sort of cryptographic assumption.}

In cryptography, we generally prove these security
claims by \emph{reduction}: we will show that
if there exists an efficient adversary $\calA$
that breaks the security of our scheme,
then we can construct an efficient adversary $\calB$ 
that breaks one of our assumptions.
If we do this, we have reached a contradiction to one
of our assumptions, so the first adversary cannot exist.

\begin{proof}[Proof of Claim]
Suppose there exists an adversary $\A$ that wins the 
one-time-security game of \cref{def:sig-once} with non-negligible probability $\epsilon$.
That is, the adversary can produces $(m^*, \sig^*)$ such that $\Ver(\vk, m^*, \sig^*) = 1$ and $m \neq m^*$ given only $\sig = \Sign(\sk, m)$.
We can then construct an adversary $\B$ that can use $\A$ to 
invert the one-way function.

\marginnote{Lamport's construction shows that if one-way functions
exist, then so do digital signatures.
Can you show that if digital signatures exist, then so do one-way
functions?}

In particular, our adversary $\calB$ will use algorithm $\calA$
as a subroutine to invert the one-way function.
We will show that if $\calA$ wins in the one-time signature security
game often, then algorithm $\calB$ will invert the one-way function
often, which is a contradiction.

Assume our one-way function is of the form $f \colon \calX \to \calY$
and that the Lamport signature scheme is on $n$-bit messages.
The one-way-function adversary $\calB$ operates as follows:
\begin{itemize}[noitemsep]
  \item The adversary $\calB$ is given a point $y \in \calY$
    and its task is to produce a preimage of $y$ under $f$. 
  \item The adversary $\calB$ generates a signing keypair as follows:
    \begin{itemize}[noitemsep]
      \item It runs the key-generation algorithm for the Lamport signature scheme $(\sk, \vk) \gets \Gen()$.
      \item The adversary chooses a random value $i^* \getsr \{1, \dots, n\}$
            and a random bit $\beta^* \getsr \zo$.
          \item The adversary sets $\vk_{i^*,\beta^*} \gets y$.
            That is, it inserts the one-way-function point it must invert
            into a random location in the verification key.
    \end{itemize}
  \item The adversary then sends the verification key $\vk$ to the Lamport-signature adversary $\calA$.
  \item The adversary $\calA$ asks for the signature on a message $m = m_1 m_2 \dots m_n \in \zon$.
  \item If $m_{i^*} = \beta^*$, then algorithm $\calB$ cannot produce a valid signature on the message
        $m$ and it outputs FAIL.
  \item Otherwise, the algorithm $\calB$ returns the signature $\sigma = (\sk_{1,m_1}, \dots, \sk_{n,m_n}) \in \calX^n$
        to algorithm $\calA$.
  \item Algorithm $\calA$ then produces a forged message-signature pair $(m^*, \sigma^*)$,
        where $m \neq m^*$.
  \item Algorithm $\calB$ parses $m^* = m^*_1 \dots m^*_n \in \zon$
        and $\sigma^* = \sigma^*_1 \dots \sigma^*_n \in \calX^n$. Then:
        \begin{itemize}[noitemsep]
          \item If $m_{i^*} = m_i$, algorithm $\calB$ outputs FAIL.
          \item Otherwise, algorithm $\calB$ outputs $x \gets \sigma^*_{i^*} \in \calX$.
        \end{itemize}
\end{itemize}

First, notice that whenever $(m^*, \sigma^*)$ is a valid message-signature
pair and whenever algorithm $\calB$ does not output FAIL, algorithm $\calB$
outputs a preimage $x \in \calX$ of point $y \in \calY$ under the one-way function $f$.
That is because, by the verification relation (\ref{eq:lamport}) for Lamport signatures,
\[f(x) = f(\sigma^*_{i^*}) = \vk_{i^*,m^*_{i^*}} = \vk_{i^*, 1 - m_i} = \vk_{i^*, \beta^*} = y.\]

Now, we must show that algorithm $\calB$ does not output FAIL too often.
Since algorithm $\calB$ chooses the values $i^*$ and $\beta^*$ at random,
and since the adversary $\calA$ behavior is \emph{independent} of these values,
we can say:
  \begin{itemize}
    \item the probability of the first failure event is $1/2$,
          since there are two possible choices of $m_{i^*}$ and only 
          one of these is bad, and 
    \item the probability of the second failure event is at most $1/n$,
          since $m$ and $m^*$ must differ in at least one of $n$ bits,
          and there is a $1/n$ probability that this differing bit is
          at index $i^*$.
  \end{itemize}

The events that $\calA$ breaks the signature scheme
and that either of these failures occur are all \emph{independent}.
Then if $\calA$ breaks the one-way function with probability $\epsilon$,
our one-way-function adversary $\calB$
inverts the one-way function with probability
\[ \epsilon_\text{one-way} = \epsilon \cdot \frac{1}{2} \cdot \frac{1}{n}.\]

The probability of either bad is at most $1/2 + 1/n$,
by the union bound.
Therefore if algorithm $\calA$ breaks one-time security of Lamport's
scheme with probability $\epsilon$,
If $\epsilon$ is non-negligible, then $\epsilon_\text{one-way} = \epsilon/2n$
is also non-negligible, and we have a contradiction.
\end{proof}

% LECTURE 6

\section{A one-time signature scheme for arbitrary-length messages}
In the Lamport signature scheme (\cref{sec:lamport}), the length of the keys scales with the size of the message being signed.
To adapt our scheme from above into a scheme that works on arbitrary-length messages without the key growing arbitrarily large, we will use a strategy called \emph{hash-and-sign}.\marginnote{Essentially all signature schemes used in practice use this hash-and-sign construction.}
In essence, the signing algorithm will pass the message through a hash function to generate a fixed-size digest before applying a signature
scheme that works only on fixed-length messages.

This paradigm is called ``hash and sign,'' and is very common.
In practice, hashing is computationally cheap operation while signing turns out to be computationally relatively expensive.
So it is common to hash a message before signing it in order to reduce the size of the message that must be signed. 

The following claim gives the general construction: 

\begin{claim}[Hash-and-sign paradigm]
Given a collision-resistant hash function $h: \bin^* \rightarrow \bin^{n}$ and a signature scheme $(\Gen, \Sign, \Ver)$ for message space $\calM = \bin^n$ (such as the one in \cref{sec:lamport}), there exists a signature scheme $(\Gen', \Sign', \Ver')$ for $\calM' = \bin^*$ as follows:

\begin{itemize}
  \item $\Gen' \deq \Gen$. The key-generation algorithm is unchanged.
	\item $\Sign'(\sk, m) \deq \Sign(sk, h(m))$. We hash the message using the hash function $h$ before passing the hashed message to the original signing function.
	\item $\Ver'(\vk, m, \sig) \deq \Ver(\vk, h(m), \sig)$. We use the original $\Ver$ to check that the tag matches \emph{hash} of the original message.
\end{itemize}
\end{claim}

\subsubsection{Security Intuition}
Suppose that there exists an efficiency adversary that breaks $(\Gen', \Sign', \Ver')$.
In particular, given $((m_1, \sig_1, \ldots, (m_t, \sig_t))$, the adversary is able to construct a valid
message-signature pair $(m^*, \sig^*)$ such that $m^* \notin \set{m_1, \ldots, m_t}$.
There are then two cases: 

\begin{enumerate}
	\item $h(m^*) \in \set{h(m_1), \ldots, h(m_t)}$. If this is the case, there is some $i \in [t]$ such that $h(m^*) = h(m_i)$. However, $h$ is collision-resistant as in the definition, so this is a contradiction!
	\item $h(m^*) \notin \set{h(m_1), \ldots, h(m_t)}$. Since the message that we pass to the underlying signature scheme is $h(m)$, this means that the adversary has found a valid signature for $h(m)$ under the original scheme $(\Gen, \Sign, \Ver)$ after seeing only signatures of $h(m_1)\neq h(m), \ldots, h(m_t)\neq h(m_t)$. This breaks the security of the underlying signature scheme, which is a contradiction!
\end{enumerate}

\subsubsection{Application to Lamport}
We can apply the hash-and-sign paradigm to the Lamport signature scheme from \cref{sec:lamport}.
We can fix our input to the Lamport scheme at, for example, 256 bits, and then run messages through a hash function that outputs 256 bits before passing them to the Lamport scheme.
This gives a \emph{one-time-secure} signature scheme for messages of arbitrary length.

\subsubsection{Security implications of hash and sign}
\marginnote{Recall that we faced a similar problem in our MAC construction. Why not use hash and MAC there? The reason is that we used AES as our PRF, which takes input of $\bin^{128}$. As explained by the birthday paradox, it is possible to find a collision in an output space of size $2^{128}$ in only time $2^{64}$! This does not provide sufficient security for practical use, as it would be quite practical to find collisions. If we had a version of AES that outputted 256 bits, we could indeed apply hash and sign.

Another reason to not use hash and MAC is that MACs can be faster to compute than collision-resistant hash functions.}

In practice, hash-and-sign can actually \emph{increase} the security of our signature scheme, in a certain sense. As shown in case 2 above, it is absolutely crucial that the hash function used is collision-resistant: if not, an adversary can find messages that cause collisions, and then a signature for one message will also be a valid signature for the other. However, in practice we often think of hash functions like SHA2 as behaving like \emph{random oracles}.
That is, for a hash function $h \colon \zo^* \to \zo^\lambda$ and a string $x \in \zo^*$ we think of the value $h(x)$ as being an independently
sampled and uniformly random value from the co-domain of the hash function, $\zo^\lambda$.\marginnote{A real-world hash function
is \emph{never actually} a random oracle. A random oracle from $h \colon \zo^* \to \zo^\lambda$
would take infinitely many bits to describe, while real-world hash functions have finite size (and polynomial-size descriptions).}

Recall that the standard security definition for
digital signatures (\cref{def:sig-sec}) allows
the attacker to request signatures on messages
of its choice.
If we pass a message through a hash function before signing
it using an underlying signature scheme scheme, however, 
we effectively randomize the message---the adversary can no longer control the
input to the underlying signature scheme. This allows us to define
another meaningful definition of security:

\begin{definition}[Digital signatures: security against random message attacks]
Any efficient adversary given the public verification key and a list of random message-signature pairs $((m_1, \sig_1), \ldots, (m_t, \sig_t))$ cannot generate a forged
message-signature pair $(m^*, \sig^*)$ 
such that $\Ver(\vk, m^*, \sig^*) = 1$ and $m^* \notin \set{m_1, \ldots, m_t}$.
\iffalse
For all efficient adversaries $\calA$:
  \[\Pr\left[ \Ver(\vk, m^*, \sig^*) = 1 \colon 
\begin{aligned}
  (\sk, \vk) &\gets \Gen()\\
  m_i &\getsr \calM \text{, for $i \in \{1, \dots, t\}$}\\
  \sig_i &\gets \Sign(\sk, m_i) \text{, for $i \in \{1, \dots, t\}$}\\
  (m^*, \sigma^*) &\gets \calA\big((m_1, \sig_1), \dots, (m_t, \sig_t) \big)
\end{aligned} \right] \]
\fi
\end{definition}

Note that this definition is \emph{not} good enough on its own---an adversary often does have the ability to generate signatures for messages of his choice. However, paired with a hash function modeled as a random oracle, this definition becomes very useful---if the inputs are passed through the hash function before they are passed to the signature scheme, they become effectively random. We can even relax the definition further without losing practicality: by the same logic, with hash function in front of the signature scheme, what the adversary needs to sign is really not a message of their choise, but is the \emph{hash} of a message of their choice---effectively a random value.

\begin{definition}[Digital signatures: random security against random message attacks] \label{def:signatures_random_security}
	Any efficient adversary given $\vk$ and a list of random message-signature pairs $((m_1, \sig_1), \ldots, (m_t, \sig_t))$ and random $m^* \notin \set{m_1, \ldots, m_t}$ cannot generate $\sig^*$ such that $\Ver(\vk, m^*, \sig^*) = 1$.
\end{definition}

It is possible to formally argue that given a signature scheme satisfying \cref{def:signatures_random_security} and a random oracle, we can construct a scheme satisfying existential unforgeability under chosen message attacks.

\section{From one-time security to many-time security}
\label{sec:sig:manytime}
After applying the hash-and-sign strategy above to our Lamport scheme, we have a signature scheme that is one-time secure for messages of arbitrary length. In order for the scheme to be useful and satisfy our security definition, we need to be able to sign polynomially many messages with a single key pair. To do this, we will use a construction very similar to he Merkle tree construction we have seen before.

We will show how to do this for a message space of
size $\bin^n$, but hash and sign can be applied to
make this work for arbitrary-length messages. 


\begin{claim}
Assume that we are given:
\begin{compactitem}
  \item a pseudorandom function, and 
  \item a one-time secure signature scheme $(\Gen_0, \Sign_0, \Ver_0)$.
\end{compactitem}
Then, for any $t \geq 0$, we can construct a many-time secure 
signature scheme $(\Gen_t, \Sign_t, \Ver_t)$ on message space $\zo^{t}$,
where the running time of all algorithms on 
security parameter $\lambda$ is $\poly(\lambda, t)$.
\end{claim}

By taking $t \approx 256$, and combining this signature
scheme with the hash-and-sign paradigm, 
we can get a many-time-secure signature scheme 
for arbitrary-length messages.

\begin{proof}[Proof (Informal)]
By induction on $t$.

\paragraph{Base case ($t=0$).}
The signature scheme is just $(\Gen_0, \Sign_0, \Ver_0)$.

\paragraph{Induction step.}
Assume the claim for $t-1$.
Then we construct the signature scheme for $t$.

Let the PRF keyspace be $\calK$.
For a PRF key $k \in \calK$ and string $s$, we write $\Gen_0^{F(k, s)}()$
to indicate the process of running the key-generation algorithm
$\Gen_0$ using randomness derived from the output of the PRF $F(k, s)$.

We have:
\begin{framed}
\begin{itemize}
  \item $\Gen_t() \to (\sk, \vk)$:
    \begin{itemize}
      \item Sample a fresh PRF key $k \getsr \calK$.
      \item Set $(\sk_\epsilon, \vk_\epsilon) \gets \Gen_0^{F(k, \text{``''})}()$.
      \item Output $(\sk, \vk) \gets ((\sk_\epsilon, k), \vk_\epsilon)$.
    \end{itemize}

  \item $\Sign_t((\sk_\epsilon, k), m) \to \sigma$: 
    \begin{itemize}
      \item Write the message $m$ as bits $(m_1, \dots, m_t) \in \zo^t$.
      \item Compute $(\sk_0, \vk_0) \gets \Gen_0^{F(k, \text{``0''})}()$
      and $(\sk_1, \vk_1) \gets \Gen_0^{F(k, \text{``1''})}()$.
      \item Set $\sigma_\epsilon \gets \Sign_0(\sk_\epsilon, \vk_0 \| \vk_1)$.
      \item Set $\sigma_m \gets \Sign_{t-1}(\sk_{m_1}, m_{2}m_3 \dots m_t)$.
      \item Output $\sigma \gets (\vk_0, \vk_1, \sigma_\epsilon, \sigma_m)$.
    \end{itemize}
  \item $\Ver_t(\vk_\epsilon, m, \sigma) \to \zo$:
    \begin{itemize}
      \item Parse $(\vk_0, \vk_1, \sigma_\epsilon, \sigma_m) \gets \sigma$.
      \item Output ``1'' if and only if 
        \begin{itemize}
          \item $\Ver_0(\vk_\epsilon, \vk_0 \| \vk_1, \sigma_\epsilon)$
        and 
      \item $\Ver_{t-1}(\vk_{m_1}, m_2m_3\dots m_n, \sigma_m)$.
        \end{itemize}
    \end{itemize}
\end{itemize}
\end{framed}

The efficiency claim follows by inspection.
To sketch the security proof: 
In a forged message-signature pair, consider
the pair $(\vk_0,\vk_1)$. Either 
\begin{itemize}
  \item These keys are different from those that the signer generated.
        In this case, the adversary has broken the one-time signature scheme. Or:
  \item These keys are the same as those that the signer generated.
        In this case, the adversary has broken the signature 
        scheme for $(t-1)$-bit messages. This violates the induction hypothesis.
\end{itemize}
Either way, we get a contradiction.
So we have (informally) proved the claim.
\end{proof}
\iffalse

We
will first show an inefficient construction, and
then use a pseudorandom to make it practical.

We first generate a single key pair for every possible message in the message space: $2^n$ total $(\sk_i^n, \vk_i^n)$ pairs for $i \in \bin^n$. These will be the leaves of our tree. For every two adjacent keys, we will then generate a key pair ($2^{n-1}$ pairs total) Then continue for all $j \in [0, \ldots, n]$, where the keys for each $j$ form layer $n-j$ of the tree (with leaves at level $n$).

% TODO: diagram of tree

As an example, to construct a hash function for 2-bit messages:

\begin{figure}[htpb]
	\centering
	\begin{subfigure}{.5\textwidth}
		\centering
		\begin{forest}
			[$\sk_\varepsilon$
				[ $\sk_0 $ 
					[ $\sk_{00}$ ]
					[ $\sk_{01}$ ]
				]
				[ $ \sk_1 $ 
					[ $\sk_{10}$ ]
					[ $\sk_{11}$ ]
				]
			]
		\end{forest}
		\caption{A subfigure}
		\label{fig:sub1}
	\end{subfigure}%
	\begin{subfigure}{.5\textwidth}
		\centering
		\begin{forest}
			[$\sk_\varepsilon$
				[ $\sk_0 $ 
					[ $\sk_{00}$ ]
					[ $\sk_{01}$ ]
				]
				[ $ \sk_1 $ 
					[ $\sk_{10}$ ]
					[ $\sk_{11}$ ]
				]
			]
		\end{forest}
		\caption{A subfigure}
		\label{fig:sub2}
	\end{subfigure}
	\caption{A figure with two subfigures}
	\label{fig:test}
\end{figure}

Importantly, every key in the tree will be used to sign only one message ever: the key at non-leaf nodes will only ever sign the pair of its children, and the key at leaf nodes will only ever be used to sign the corresponding message. 

To sign a given message, we generate the signature by providing the actual signature of $\vk_m$ over $m$ \emph{alongside} the remainder of the verification keys and signatures needed to trace all the way back up to the root verification key $\vk_\varepsilon$.

% TODO: finish this explanation.

\subsection{Improving Inefficiency}
In the scheme above, we required $O(2^n)$ keys for our secret key. This is far too many keys to be pracical, but we still need to be able to use each of these keys to sign a given message. To bridge this gap, we will use a PRF to generate these secret keys \textquote{on the fly} and use those secret keys to generate the corresponding verification key.

\fi

\section{Choosing Signature Schemes}
The signature scheme we presented in \cref{sec:sig:manytime}
is not particularly efficient in terms of signature size.

\begin{table}[htpb]
	\centering
	\caption{Statistics about various signature schemes used in practice}
	\label{tab:sig_schemes}

	\begin{tabular}{rcccc}
		\textbf{Algorithm} & $\vk$ size & $\sig$ size & signatures/sec & verifications/sec \\
		\bf{SPHINCS+-128} & 32 B & 8000 B & 5 & 750 \\
		\bf{RSA 2048} & 256 B & 256 B & 2,000 & 50,000 \\
		\bf{ECDSA256} & 32 B & 64 B & 42,000 & 14,000 \\
	\end{tabular}
\end{table}

Many deployed systems today use the ECDSA256 signature scheme.
Legacy application still use RSA signatures, though because of their
relatively large public-key and signature sizes, few new applications
use these schemes.\marginnote{Hashing is much, much faster than signing---the commonly used SHA256 hashing algorithm can compute around 10,000,000 hashes per second. 
This is one reason the hash-and-sign paradigm 
is so useful.
}
